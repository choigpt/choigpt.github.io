---
layout: post
title: "Skip Connection (잔차 연결)"
date: 2026-02-25 00:00:00
tags: [딥러닝, ML-AI, ResNet]
category: ML-AI
---

Skip Connection(잔차 연결)은 딥러닝 네트워크에서 **입력을 레이어를 건너뛰어 출력에 직접 더하는 구조**다. ResNet에서 처음 제안되어 현대 딥러닝의 핵심 기법이 되었다.

## 기본 구조

일반 레이어가 `F(x)`를 학습한다면, Skip Connection이 있는 블록은 다음을 학습한다.

$$H(x) = F(x) + x$$

`x`가 출력에 그대로 더해지기 때문에, 실제로 레이어가 배워야 하는 건 **F(x) = H(x) - x**, 즉 **잔차(Residual)**다.

## 왜 필요한가?

네트워크가 깊어질수록 역전파 시 그레디언트가 소실되는 **기울기 소실(Vanishing Gradient)** 문제가 발생한다.

Skip Connection은 그레디언트가 역전파될 때 중간 레이어를 건너뛰고 **직접 경로(identity shortcut)**를 통해 흐를 수 있도록 해서 이 문제를 완화한다.

## 항등 행렬과 영 행렬

- 레이어가 **아무것도 배우지 못했을 때** F(x) = 0 (영행렬) → H(x) = x (입력 그대로 전달)
- 레이어가 **항등 변환**을 배우는 것보다 **잔차만 0으로 만드는 것**이 훨씬 쉽다

이것이 깊은 네트워크를 더 쉽게 최적화할 수 있는 이유다.

## 효과

- 100층 이상의 매우 깊은 네트워크 학습 가능
- 학습 속도 향상
- 성능 저하 없이 네트워크 깊이 증가 가능

ResNet-50, ResNet-101 등이 모두 이 구조를 기반으로 한다.
